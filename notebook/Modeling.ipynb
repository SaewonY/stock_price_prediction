{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "### 1.  [Introduction](#1.-Introduction)\n",
    "### 2.  [Import Libraries](#2.-Import-Libraries)\n",
    "### 3.  [Helper Functions](#3.-Helper-Functions)\n",
    "### 4.  [Load Dataset](#4.-Load-Dataset)\n",
    "### 5.  [Dataset Preprocess](#5.-Dataset-Preprocess)\n",
    "### 6.  [Validation Strategy](#6.-Validation-Strategy)\n",
    "### 7.  [Tree based Model](#7.-Tree-based-Model)\n",
    "### 8.  [MLP based Model](#8.-MLP-based-Model)\n",
    "### 9.  [RNN based Model](#9.-RNN-based-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번 노트북을 통해서는 시계열 데이터를 어떻게 모델링할 수 있는가에 대해서 살펴보고자 한다.\n",
    "<br>\n",
    "- 보통 EDA만 노트북으로 작성하고 그 외의 작업들은 script로 하기 때문에 이 보다는 보기 좋을 것으로 생각합니다.\n",
    "<br>\n",
    "- 노트북을 통해 tree 계열의 모델링을 하는 전반적인 코드를 작성하였고, 이뿐만 아니라 MLP, RNN과 같은 딥러닝 계열의 모델링 파이프라인을 작성하였다.\n",
    "<br>\n",
    "- 데이터 전처리, 파생 변수 생성, 검증 전략부터 모델링까지 순차적으로 작성했으며, tree 계열과 mlp 기반의 모델링은 classification으로, RNN은 regression 문제로 코드를 작성하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 설명**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Input Data** <br>\n",
    "데이터셋의 각 column은 날짜정보와 종목정보, 그리고 Feature set으로 이루어져 있다. Feature set은 blur 처리되어 있으며,\n",
    "Feature는 각 종목들의 유의미하다고 판단되는 데이터 값으로 이루어져 있다.\n",
    "- **Target Data** <br>\n",
    "Train set에 대해서는 정답 데이터 2개가 주어진다.\n",
    "정답 데이터들은 각 샘플 시간 기준으로 다음 단위시간(T) 수익률로 만들어져있다. <br>\n",
    "정답 데이터1: 단위시간(T) 수익률 (train_target.csv) -> Regression <br>\n",
    "정답 데이터2: 특정 한 시점에서 종목들의 단위 시간 수익률(정답데이터 1)을 5분위로 나누어 분류한 Target (train_target2.csv) -> Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:42:51.474951Z",
     "start_time": "2020-02-02T04:42:50.495642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext line_profiler\n",
    "%matplotlib inline\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import numexpr\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn, cuda\n",
    "from torch.nn import functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch.optim import Adam, SGD, Optimizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험의 재생산을 위한 seed값 고정 함수\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 인코딩 (train과 test의 종목 합쳐서 진행)\n",
    "def encode_LE(col, train, test, verbose=True):\n",
    "    df_comb = pd.concat([train[col],train[col]],axis=0)\n",
    "    df_comb,_ = df_comb.factorize(sort=True)\n",
    "    nm = col + '_encoded'\n",
    "    if df_comb.max() > 32000: \n",
    "        train[nm] = df_comb[:len(train)].astype('int32')\n",
    "        test[nm] = df_comb[len(train):].astype('int32')\n",
    "    else:\n",
    "        train[nm] = df_comb[:len(train)].astype('int16')\n",
    "        test[nm] = df_comb[len(train):].astype('int16')\n",
    "    del df_comb; x = gc.collect()\n",
    "    if verbose: print(nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Column을 기준으로 agg하는 함수 - ex) code (종목)별로 평균 F 피쳐 값을 계산으로써 파생 변수를 생성해 모델에 종목 정보를 제공해줄 수 있다\n",
    "def code_agg(train_df, test_df, merge_columns, columns, aggs=['mean']):\n",
    "    tr, te = df_copy(train_df, test_df)\n",
    "    for merge_column in merge_columns:\n",
    "        for col in columns:\n",
    "            for agg in aggs:\n",
    "                valid = pd.concat([tr[[merge_column, col]], te[[merge_column, col]]])\n",
    "                new_cn = merge_column + '_' + agg + '_' + col\n",
    "                if agg=='quantile':\n",
    "                    valid = valid.groupby(merge_column)[col].quantile(0.8).reset_index().rename(columns={col:new_cn})\n",
    "                else:\n",
    "                    valid = valid.groupby(merge_column)[col].agg([agg]).reset_index().rename(columns={agg:new_cn})\n",
    "                valid.index = valid[merge_column].tolist()\n",
    "                valid = valid[new_cn].to_dict()\n",
    "            \n",
    "                tr[new_cn] = tr[merge_column].map(valid)\n",
    "                te[new_cn] = te[merge_column].map(valid)\n",
    "    return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_copy(tr_df, te_df):\n",
    "    tr = tr_df.copy()\n",
    "    te = te_df.copy()\n",
    "    return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use numexpr library for improved performance\n",
    "# Simple Moving Average (code 별로 계산)\n",
    "def SMA(df, target, num_windows=3):\n",
    "    arr = np.array([])\n",
    "    x = df['code_encoded'].values\n",
    "    for code in df['code_encoded'].unique():\n",
    "        temp_df = df[numexpr.evaluate(f'(x == code)')]\n",
    "        arr = np.concatenate((arr, temp_df[target].rolling(window=num_windows, min_periods=1).mean().values))\n",
    "    return arr\n",
    "\n",
    "# Exponential Moving Average (code 별로 계산)\n",
    "def EMA(df, target, span_num=3):\n",
    "    arr = np.array([])\n",
    "    x = df['code_encoded'].values\n",
    "    for code in df['code_encoded'].unique():\n",
    "        temp_df = df[numexpr.evaluate(f'(x == code)')]\n",
    "        arr = np.concatenate((arr, temp_df[target].ewm(span=span_num, min_periods=1).mean().values))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 NaN 전처리\n",
    "def preprocess_nan(df, feat_cols):\n",
    "\n",
    "    preprocessed_df = pd.DataFrame()\n",
    "\n",
    "    # code(종목)별, 피쳐별로 NaN 값을 채우되, 최근 시간에 더 가중치를 두고 계산한다.\n",
    "    for code in df['code'].unique():\n",
    "        code_df = df[df['code'] == code].copy()\n",
    "\n",
    "        for i, feat_col in enumerate(code_df[feat_cols]):\n",
    "\n",
    "            temp_df = code_df[feat_col].dropna().to_frame()\n",
    "\n",
    "            if len(temp_df) == len(code_df):\n",
    "                continue\n",
    "\n",
    "            temp_df['weight'] = [i for i in range(len(temp_df), 0, -1)]\n",
    "\n",
    "            try:\n",
    "                fill_value = np.average(temp_df[feat_col], weights=temp_df['weight'])\n",
    "                code_df[feat_col].fillna(fill_value, inplace=True)\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        preprocessed_df = preprocessed_df.append(code_df)\n",
    "        \n",
    "    del code_df, temp_df; gc.collect()\n",
    "    \n",
    "    # 해당 code(종목)의 feature에 모든 값이 NaN일 경우 모든 종목의 피쳐 평균값으로 NaN을 채운다.  \n",
    "    for feat_col in feat_cols:\n",
    "        mean_val = preprocessed_df[feat_col].mean()\n",
    "        preprocessed_df[feat_col].fillna(mean_val, inplace=True)\n",
    "\n",
    "    return preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값이 0.5 이상일 경우 1, 0.5 이하일 경우 0으로 mapping한다.\n",
    "# threshold는 수정 가능\n",
    "def to_binary(preds, threshold=0.5):\n",
    "    return np.where(preds >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 기반으로 Confusion Matrix 시각화하는 함수\n",
    "def plot_confusion_matrix(cm, target_names, title='Validation Confusion matrix', cmap=None, normalize=True):\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('OrRd_r')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단위 시간 td를 기준으로 validation set을 생성하는 위한 함수\n",
    "def make_dict(train_df, test_df, feat_cols, target):\n",
    "\n",
    "    dataset_dict = {}\n",
    "\n",
    "    # dataset 1\n",
    "    X_train1 = train_df.query(\"td <= 172\")[feat_cols].values\n",
    "    X_valid1 = train_df.query(\"td > 172 & td <= 206\")[feat_cols].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train1)\n",
    "    \n",
    "    dataset_dict['X_train1'] = scaler.transform(X_train1)\n",
    "    dataset_dict['X_valid1'] = scaler.transform(X_valid1)\n",
    "    dataset_dict['y_train1'] = train_df.query(\"td <= 172\")[target].values\n",
    "    dataset_dict['y_valid1'] = train_df.query(\"td > 172 & td <= 206\")[target].values\n",
    "    del scaler\n",
    "\n",
    "    # dataset 2\n",
    "    X_train2 = train_df.query(\"td <= 206\")[feat_cols].values\n",
    "    X_valid2 = train_df.query(\"td > 206 & td <= 240\")[feat_cols].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train2)\n",
    "    \n",
    "    dataset_dict['X_train2'] = scaler.transform(X_train2)\n",
    "    dataset_dict['X_valid2'] = scaler.transform(X_valid2)\n",
    "    dataset_dict['y_train2'] = train_df.query(\"td <= 206\")[target].values\n",
    "    dataset_dict['y_valid2'] = train_df.query(\"td > 206 & td <= 240\")[target].values\n",
    "    del scaler\n",
    "\n",
    "    # dataset 3\n",
    "    X_train3 = train_df.query(\"td <= 240\")[feat_cols].values\n",
    "    X_valid3 = train_df.query(\"td > 240 & td <= 274\")[feat_cols].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train3)\n",
    "    \n",
    "    dataset_dict['X_train3'] = scaler.transform(X_train3)\n",
    "    dataset_dict['X_valid3'] = scaler.transform(X_valid3)\n",
    "    dataset_dict['y_train3'] = train_df.query(\"td <= 240\")[target].values\n",
    "    dataset_dict['y_valid3'] = train_df.query(\"td > 240 & td <= 274\")[target].values\n",
    "\n",
    "    x_test = test_df[feat_cols].values\n",
    "    dataset_dict['x_test'] = scaler.transform(x_test)\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 받아 학습을 하는 함수. validation 방법에 따라 다르며, feature importance와 confusion matrix도 시각화해 볼 수 있다.\n",
    "def make_predictions(dataset_dict, df, feat_cols, lgb_params, valid_type='hold_out', plot_importance=True, plot_confusion=True):\n",
    "\n",
    "    x_test = dataset_dict['x_test']\n",
    "    if valid_type == 'hold_out':\n",
    "        X_train = dataset_dict['X_train3']\n",
    "        y_train = dataset_dict['y_train3']\n",
    "        X_valid = dataset_dict['X_valid3']\n",
    "        y_valid = dataset_dict['y_valid3']\n",
    "        \n",
    "        trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_valid, label=y_valid) \n",
    "\n",
    "        clf = lgb.train(\n",
    "            lgb_params,\n",
    "            trn_data,\n",
    "            valid_sets = [trn_data, val_data],\n",
    "            verbose_eval = 100 ,\n",
    "        )   \n",
    "        \n",
    "        valid_preds = clf.predict(X_valid)\n",
    "        preds = clf.predict(x_test)\n",
    "        \n",
    "        print()\n",
    "        print(\"roc_auc_score: {:.4f}\".format(roc_auc_score(y_valid, valid_preds)))\n",
    "        print(\"accuracy_score: {:.4f}\".format(accuracy_score(y_valid, to_binary(valid_preds, 0.5))))\n",
    "\n",
    "        if plot_importance:\n",
    "            \n",
    "            feature_importance_df = pd.DataFrame()\n",
    "            feature_importance_df[\"Feature\"] = feat_cols\n",
    "            feature_importance_df[\"Importance\"] = clf.feature_importance()\n",
    "            \n",
    "            cols = (feature_importance_df[[\"Feature\", \"Importance\"]]\n",
    "                .groupby(\"Feature\")\n",
    "                .mean()\n",
    "                .sort_values(by=\"Importance\", ascending=False).index)\n",
    "\n",
    "            best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(14,10))\n",
    "            sns.barplot(x=\"Importance\",\n",
    "                        y=\"Feature\",\n",
    "                        data=best_features.sort_values(by=\"Importance\",\n",
    "                                                       ascending=False)[:20], ci=None)\n",
    "            plt.title('LightGBM Feature Importance', fontsize=20)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "        if plot_confusion:\n",
    "            plot_confusion_matrix(confusion_matrix(y_valid, to_binary(valid_preds, 0.5)), \n",
    "                          normalize    = False,\n",
    "                          target_names = ['pos', 'neg'],\n",
    "                          title        = \"Confusion Matrix\")\n",
    "    \n",
    "    elif valid_type == 'sliding_window':\n",
    "        \n",
    "        window_num = 3\n",
    "        acc = 0\n",
    "        auc = 0\n",
    "        for num in range(1, window_num+1):    \n",
    "            print(f\"num {num} dataset training starts\")\n",
    "            \n",
    "            preds = np.zeros(len(x_test))\n",
    "            X_train = dataset_dict[f'X_train{num}']\n",
    "            y_train = dataset_dict[f'y_train{num}']\n",
    "            X_valid = dataset_dict[f'X_valid{num}']\n",
    "            y_valid = dataset_dict[f'y_valid{num}']\n",
    "            trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "            val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "            clf = lgb.train(lgb_params, trn_data, valid_sets = [trn_data, val_data], verbose_eval=100)\n",
    "            valid_preds = clf.predict(X_valid)\n",
    "            preds += clf.predict(x_test) / window_num\n",
    "            acc += accuracy_score(y_valid, to_binary(valid_preds, 0.5)) / window_num\n",
    "            auc += roc_auc_score(y_valid, valid_preds) / window_num\n",
    "            print()            \n",
    "        \n",
    "        print(\"mean roc_auc_score: {:.4f}\".format(auc))\n",
    "        print(\"mean acc_score: {:.4f}\".format(acc))\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improved version of adam optimizer\n",
    "class AdamW(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
    "                 weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('AdamW does not support sparse gradients, please consider SparseAdam instead')\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                # according to the paper, this penalty should come after the bias correction\n",
    "                # if group['weight_decay'] != 0:\n",
    "                #     grad = grad.add(group['weight_decay'], p.data)\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p.data.add_(-group['weight_decay'], p.data)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Layer Perceptron baseline model (further improvements needed)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_classes=1, num_feats=47):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_classes = num_classes         \n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Linear(num_feats, 1024),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, self.num_classes)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.mlp_layers(x)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array를 받아 dataset으로\n",
    "class Stock_mlp_dataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.X_dataset = []\n",
    "        self.Y_dataset = []\n",
    "        for x in X:\n",
    "            self.X_dataset.append(torch.FloatTensor(x))\n",
    "        try:\n",
    "            for y in Y:\n",
    "                self.Y_dataset.append(torch.tensor(y))\n",
    "        \n",
    "        # test set의 경우엔 라벨이 없음\n",
    "        except:\n",
    "#             print(\"no_label\")\n",
    "            pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.X_dataset[index]\n",
    "        # train, valid set\n",
    "        try:\n",
    "            target = self.Y_dataset[index]\n",
    "            return inputs, target\n",
    "        # test set\n",
    "        except:\n",
    "            return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataset load 함수 (dataset => dataloader 반환)\n",
    "def build_dataloader(X, Y, batch_size, shuffle=False):\n",
    "    \n",
    "    dataset = Stock_mlp_dataset(X, Y)\n",
    "    dataloader = DataLoader(\n",
    "                            dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            num_workers=2\n",
    "                            )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model build 함수 \n",
    "def build_model(device, model_name='MLP', num_classes=1, num_feats=47):\n",
    "    if model_name == 'MLP':\n",
    "        model = MLP(num_classes, num_feats)\n",
    "#     모델 추가 가능\n",
    "#     elif model_name == '':\n",
    "#         model = _\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매 epoch마다 validation을 진행, 각종 metric의 score를 반환\n",
    "def validation(model, criterion, valid_loader, use_cuda):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    valid_preds = []\n",
    "    valid_targets = []\n",
    "    val_loss = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, target) in enumerate(train_loader):\n",
    "\n",
    "            target = target.reshape(-1, 1).float()\n",
    "            valid_targets.append(target.numpy().copy())\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs = inputs.to(device)\n",
    "                target = target.to(device)       \n",
    "                    \n",
    "            output = model(inputs)\n",
    "            \n",
    "#             print(output[:10])\n",
    "#             print(target[:10])\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            valid_preds.append(output.detach().cpu().numpy())\n",
    "            \n",
    "            val_loss += loss.item() / len(valid_loader)\n",
    "     \n",
    "    # to_binary 함수를 통해 0과 1 사이의 아웃풋을 0과 1로 매핑\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    valid_targets = np.concatenate(valid_targets)\n",
    "    acc = accuracy_score(valid_targets, to_binary(valid_preds))\n",
    "    roc_auc = roc_auc_score(valid_targets, valid_preds)\n",
    "    recall = recall_score(valid_targets, to_binary(valid_preds)) \n",
    "    precision = precision_score(valid_targets, to_binary(valid_preds)) \n",
    "    \n",
    "    return val_loss, acc, roc_auc, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 학습하는 함수\n",
    "def train_mlp_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, use_cuda, verbose_epoch=20, path='best_model.pt'):\n",
    "    \n",
    "    best_valid_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch_idx, (inputs, target) in enumerate(train_loader):\n",
    "\n",
    "            target = target.reshape(-1, 1).float()\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs = inputs.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        # validation 진행\n",
    "        val_loss, acc_score, auc_score, recall, precision = validation(model, criterion, valid_loader, use_cuda)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        lr = [_['lr'] for _ in optimizer.param_groups]\n",
    "\n",
    "        if epoch % verbose_epoch == 0:\n",
    "            print('\\nEpoch [{}/{}]  train Loss: {:.3f}  val_loss: {:.3f}  accuracy: {:.3f}  roc_auc: {:.3f}  recall: {:.3f}  precision: {:.4f}  lr: {:.7f}  elapsed: {:.0f}m {:.0f}s' \\\n",
    "                  .format(epoch,  num_epochs, train_loss, val_loss, acc_score, auc_score, recall, precision, lr[0], elapsed // 60, elapsed % 60))\n",
    "        \n",
    "        model_path = output_dir / path\n",
    "\n",
    "        # validation accuracy가 최대일 때 모델 저장\n",
    "        if acc_score > best_valid_acc:\n",
    "            best_epoch = epoch\n",
    "            best_valid_acc = acc_score\n",
    "            roc_auc_score = auc_score\n",
    "            recall_ = recall\n",
    "            precision_ = precision\n",
    "        \n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        # 50 epoch 동안 개선이 없으면 학습 강제 종료\n",
    "        if count == 50:\n",
    "            print(\"not improved for 50 epochs\")\n",
    "            break\n",
    "        if acc_score < best_valid_acc:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "            \n",
    "        # learning_rate scheduling based on accuracy score\n",
    "        scheduler.step(acc_score)\n",
    "            \n",
    "    print(\"\\n- training report\")\n",
    "    print(\"best epoch: {}\".format(best_epoch))\n",
    "    print(\"accuracy: {:.4f}\".format(best_valid_acc))\n",
    "    print(\"roc_auc_score: {:.4f}\".format(roc_auc_score))\n",
    "    print(\"recall score: {:.4f}\".format(recall_))\n",
    "    print(\"precision score: {:.4f}\\n\".format(precision_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_inference(model, test_loader, batch_size, use_cuda):\n",
    "    \n",
    "    test_preds = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            if use_cuda:\n",
    "                data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            test_preds.append(outputs.detach().cpu().numpy())\n",
    "            \n",
    "    test_preds = np.concatenate(test_preds)\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm 모델 학습 (하나의 code만)\n",
    "def train_lstm_model(model, data_loader, criterion, num_epochs, verbose_eval, model_path):\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "    best_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = 0\n",
    "\n",
    "        for i, (X, Y) in enumerate(data_loader):\n",
    "            X = X.float()\n",
    "            Y = Y.float()\n",
    "            if use_cuda:\n",
    "                X = X.to(device)\n",
    "                Y = Y.to(device)\n",
    "            output = model(X) \n",
    "\n",
    "            loss = 0\n",
    "            preds = []\n",
    "            for i, y_t in enumerate(Y.chunk(Y.size(1), dim=1)):\n",
    "                loss += criterion(output[i], y_t)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item() / len(data_loader)\n",
    "\n",
    "        # train loss가 낮을 때 모델 저장\n",
    "        if train_loss < best_loss:\n",
    "            best_epoch = epoch\n",
    "            best_loss = train_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        if epoch % (verbose_eval) == 0:\n",
    "            print(\"Epoch [{}/{}]  train_loss: {:.5f}\".format(epoch, num_epochs, train_loss))    \n",
    "\n",
    "    print(\"\\nBest epoch: {}  Best Loss: {:.5f}\".format(best_epoch, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 코드의 데이터를 불러와 scaling => 이후 Stock_lstm_dataset 함수에 인풋으로 전달\n",
    "def prepared_code_data(df, code, feat_cols, seq_len=12):\n",
    "    \n",
    "    temp_df = df[df['code']==code][feat_cols+['target']].reset_index(drop=True)\n",
    "\n",
    "    X = temp_df[feat_cols].values\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    Y = temp_df['target'].values\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm을 위한 데이터셋 생성 함수\n",
    "class Stock_lstm_dataset(Dataset):\n",
    "    def __init__(self, X, Y, seq_len):\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        for i in range(len(X) - seq_len):\n",
    "            self.X.append(X[i : i + seq_len])\n",
    "            self.Y.append(Y[i : i + seq_len])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = torch.tensor(self.X[index])\n",
    "        targets = torch.tensor(self.Y[index])\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple rnn based model (further improvements needed)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, bidirectional=False, batch_first=True)\n",
    "        self.lstm1 = nn.LSTM(self.hidden_size, self.hidden_size, bidirectional=False, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i, x_t in enumerate(x.chunk(x.size(1), dim=1)):\n",
    "            h_lstm1, _ = self.lstm(x_t)\n",
    "            h_lstm2, _ = self.lstm1(h_lstm1)\n",
    "            output = self.linear(h_lstm2)\n",
    "            outputs += [output.squeeze(-1)]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm 모델의 inference 함수\n",
    "def lstm_predict(model, X, seq_len):\n",
    "    i = 0\n",
    "    result = []\n",
    "    while (i < X.shape[0]):\n",
    "\n",
    "        batch_end = i + seq_len\n",
    "\n",
    "        if batch_end > X.shape[0]:\n",
    "            batch_end = X.shape[0]\n",
    "        x_input = torch.tensor(X[i: batch_end])\n",
    "\n",
    "        if x_input.dim() == 2:\n",
    "            x_input = x_input.unsqueeze(0)\n",
    "\n",
    "        x_input = x_input.float()\n",
    "        if use_cuda:\n",
    "            x_input = x_input.to(device)\n",
    "\n",
    "        output = model(x_input)\n",
    "        for value in output:\n",
    "            result.append(value.item())\n",
    "\n",
    "        i = batch_end\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 종목을 학습하고 이를 시각화까지 해주는 함수\n",
    "def lstm_train_visualize(train_df, code, feat_cols, num_epochs, seq_len, verbose_eval=20, plot_prediction=True):\n",
    "    X, Y = prepared_code_data(train_df, code, feat_cols, seq_len)\n",
    "\n",
    "    dataset = Stock_lstm_dataset(X, Y, seq_len=seq_len)\n",
    "    data_loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    # model setting\n",
    "    INPUT_SIZE = len(feat_cols)\n",
    "    HIDDEN_SIZE = 100\n",
    "    OUTPUT_SIZE = 1\n",
    "\n",
    "    model = RNN(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    model_path = output_dir / 'rnn_best_model.pt'\n",
    "\n",
    "    train_lstm_model(model, data_loader, criterion, num_epochs, verbose_eval, model_path)\n",
    "\n",
    "    model = RNN(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    result = lstm_predict(model, X, seq_len)\n",
    "    result_df = pd.DataFrame({'td':[i for i in range(X.shape[0])], 'predicted':result, 'target':Y})\n",
    "    \n",
    "    if plot_prediction:\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        data.append(go.Scatter(\n",
    "            x = result_df['td'].values,\n",
    "            y = result_df['target'].values,\n",
    "            name = \"target\"\n",
    "        ))\n",
    "        \n",
    "        data.append(go.Scatter(\n",
    "            x = result_df['td'].values,\n",
    "            y = result_df['predicted'].values,\n",
    "            name = \"predicted\"\n",
    "        ))\n",
    "        layout = go.Layout(dict(title = f\"code: {code}\",\n",
    "                          xaxis = dict(title = 'Time'),\n",
    "                          yaxis = dict(title = 'Earning Ratio (target)'),\n",
    "                          ),legend=dict(orientation=\"h\"))\n",
    "\n",
    "        py.iplot(dict(data=data, layout=layout), filename='basic-line')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 재생산을 위한 seed값 고정\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:44:48.566933Z",
     "start_time": "2020-02-02T04:44:47.573602Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '../input/stock-price'\n",
    "\n",
    "X_train = pd.read_csv(os.path.join(DATASET_PATH, 'train_data.csv')) #훈련 데이터\n",
    "Y_train = pd.read_csv(os.path.join(DATASET_PATH,'train_target.csv')) # 훈련 데이터에 대한 정답데이터 for regression\n",
    "Y2_train = pd.read_csv(os.path.join(DATASET_PATH,'train_target2.csv')) # 훈련 데이터에 대한 정답데이터 for classification\n",
    "test_df = pd.read_csv(os.path.join(DATASET_PATH,'test_data.csv')) # 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:44:49.032462Z",
     "start_time": "2020-02-02T04:44:48.952670Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.set_index(['td', 'code'])\n",
    "Y_train = Y_train.set_index(['td', 'code'])\n",
    "Y2_train = Y2_train.set_index(['td', 'code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T04:44:49.557291Z",
     "start_time": "2020-02-02T04:44:49.389231Z"
    }
   },
   "outputs": [],
   "source": [
    "# 시각화 및 전처리부터 모델링까지 보다 편하게 수행하기 위해 새로운 데이터셋을 생성\n",
    "Y2_train = Y2_train.rename(columns={'target':'binned_target'})\n",
    "\n",
    "train_df = pd.merge(X_train, Y_train['target'], how='left', on=['td', 'code'])\n",
    "train_df = pd.merge(train_df, Y2_train['binned_target'], how='left', on=['td', 'code'])\n",
    "train_df['binary_target'] = train_df['target'].apply(lambda x: 1 if x >= 0 else 0)\n",
    "\n",
    "train_df = train_df.reset_index()\n",
    "\n",
    "train_df['td'] = train_df['td'].str[1:].astype('int')\n",
    "test_df['td'] = test_df['td'].str[1:].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>td</th>\n",
       "      <th>code</th>\n",
       "      <th>F001</th>\n",
       "      <th>F002</th>\n",
       "      <th>F003</th>\n",
       "      <th>F004</th>\n",
       "      <th>F005</th>\n",
       "      <th>F006</th>\n",
       "      <th>F007</th>\n",
       "      <th>F008</th>\n",
       "      <th>F009</th>\n",
       "      <th>F010</th>\n",
       "      <th>F011</th>\n",
       "      <th>F012</th>\n",
       "      <th>F013</th>\n",
       "      <th>F014</th>\n",
       "      <th>F015</th>\n",
       "      <th>F016</th>\n",
       "      <th>F017</th>\n",
       "      <th>F018</th>\n",
       "      <th>F019</th>\n",
       "      <th>F020</th>\n",
       "      <th>F021</th>\n",
       "      <th>F022</th>\n",
       "      <th>F023</th>\n",
       "      <th>F024</th>\n",
       "      <th>F025</th>\n",
       "      <th>F026</th>\n",
       "      <th>F027</th>\n",
       "      <th>F028</th>\n",
       "      <th>F029</th>\n",
       "      <th>F030</th>\n",
       "      <th>F031</th>\n",
       "      <th>F032</th>\n",
       "      <th>F033</th>\n",
       "      <th>F034</th>\n",
       "      <th>F035</th>\n",
       "      <th>F036</th>\n",
       "      <th>F037</th>\n",
       "      <th>F038</th>\n",
       "      <th>F039</th>\n",
       "      <th>F040</th>\n",
       "      <th>F041</th>\n",
       "      <th>F042</th>\n",
       "      <th>F043</th>\n",
       "      <th>F044</th>\n",
       "      <th>F045</th>\n",
       "      <th>F046</th>\n",
       "      <th>target</th>\n",
       "      <th>binned_target</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A005</td>\n",
       "      <td>7.267364</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.945559</td>\n",
       "      <td>-0.828748</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>-0.038719</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>-1.015634</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>71526.60</td>\n",
       "      <td>0.100316</td>\n",
       "      <td>-4.768937</td>\n",
       "      <td>4.792733</td>\n",
       "      <td>-0.043790</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>38.238227</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>-6.925412</td>\n",
       "      <td>-0.041526</td>\n",
       "      <td>6.302427</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>3.270022</td>\n",
       "      <td>-0.011596</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>5.016722</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>12.749842</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.137546</td>\n",
       "      <td>48.333700</td>\n",
       "      <td>-0.043457</td>\n",
       "      <td>-1.567398</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>-1.041667</td>\n",
       "      <td>13.357401</td>\n",
       "      <td>0.793424</td>\n",
       "      <td>11.347518</td>\n",
       "      <td>0.544470</td>\n",
       "      <td>-0.041401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A006</td>\n",
       "      <td>-7.477904</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>1.089255</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>7.640449</td>\n",
       "      <td>0.038965</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>-0.631765</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>-0.002093</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>-0.124314</td>\n",
       "      <td>66762.59</td>\n",
       "      <td>0.041121</td>\n",
       "      <td>-0.934142</td>\n",
       "      <td>3.893363</td>\n",
       "      <td>0.045088</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>2.481333</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>-1.043675</td>\n",
       "      <td>0.040733</td>\n",
       "      <td>-2.531807</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>-1.306523</td>\n",
       "      <td>0.042740</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>-2.244898</td>\n",
       "      <td>0.313152</td>\n",
       "      <td>1.775451</td>\n",
       "      <td>0.042377</td>\n",
       "      <td>-0.178182</td>\n",
       "      <td>3.555757</td>\n",
       "      <td>0.042450</td>\n",
       "      <td>-1.033058</td>\n",
       "      <td>-0.001463</td>\n",
       "      <td>-0.002713</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.004431</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>-14.464286</td>\n",
       "      <td>0.546866</td>\n",
       "      <td>-4.960317</td>\n",
       "      <td>3.914780</td>\n",
       "      <td>-0.010438</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A007</td>\n",
       "      <td>7.622525</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>1.260723</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>13.735577</td>\n",
       "      <td>0.025740</td>\n",
       "      <td>0.012530</td>\n",
       "      <td>6.140861</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.013585</td>\n",
       "      <td>-0.116173</td>\n",
       "      <td>43033.00</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>12.650914</td>\n",
       "      <td>2.044551</td>\n",
       "      <td>0.028468</td>\n",
       "      <td>0.126005</td>\n",
       "      <td>-0.001062</td>\n",
       "      <td>3.891949</td>\n",
       "      <td>0.017248</td>\n",
       "      <td>24.251223</td>\n",
       "      <td>0.024875</td>\n",
       "      <td>-0.785996</td>\n",
       "      <td>0.018240</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>9.377718</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.052338</td>\n",
       "      <td>13.965816</td>\n",
       "      <td>1.598579</td>\n",
       "      <td>-0.263783</td>\n",
       "      <td>0.017256</td>\n",
       "      <td>0.032633</td>\n",
       "      <td>4.309684</td>\n",
       "      <td>0.028468</td>\n",
       "      <td>7.648485</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>-0.000951</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.004544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.052749</td>\n",
       "      <td>0.523903</td>\n",
       "      <td>-1.228115</td>\n",
       "      <td>9.910044</td>\n",
       "      <td>-0.042630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A011</td>\n",
       "      <td>51.693204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.967351</td>\n",
       "      <td>0.268144</td>\n",
       "      <td>-11.543311</td>\n",
       "      <td>0.143675</td>\n",
       "      <td>0.033834</td>\n",
       "      <td>0.401105</td>\n",
       "      <td>0.185529</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>1.671017</td>\n",
       "      <td>5573.01</td>\n",
       "      <td>0.096411</td>\n",
       "      <td>0.076096</td>\n",
       "      <td>0.131538</td>\n",
       "      <td>0.122475</td>\n",
       "      <td>-0.097907</td>\n",
       "      <td>-0.003738</td>\n",
       "      <td>-49.948921</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>-7.443115</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>43.068155</td>\n",
       "      <td>0.034070</td>\n",
       "      <td>-0.006647</td>\n",
       "      <td>17.515292</td>\n",
       "      <td>0.088839</td>\n",
       "      <td>0.051290</td>\n",
       "      <td>56.189239</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>-7.132306</td>\n",
       "      <td>0.091060</td>\n",
       "      <td>1.545997</td>\n",
       "      <td>-36.111240</td>\n",
       "      <td>0.118397</td>\n",
       "      <td>1.358087</td>\n",
       "      <td>0.037001</td>\n",
       "      <td>-0.004078</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.012924</td>\n",
       "      <td>-7.142857</td>\n",
       "      <td>156.242771</td>\n",
       "      <td>1.050259</td>\n",
       "      <td>137.679277</td>\n",
       "      <td>-2.979930</td>\n",
       "      <td>0.109743</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A012</td>\n",
       "      <td>-7.707446</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>1.201887</td>\n",
       "      <td>0.285988</td>\n",
       "      <td>21.070234</td>\n",
       "      <td>-0.006894</td>\n",
       "      <td>0.017134</td>\n",
       "      <td>0.497051</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>-0.350090</td>\n",
       "      <td>43167.36</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>3.438244</td>\n",
       "      <td>7.199411</td>\n",
       "      <td>0.024039</td>\n",
       "      <td>0.107034</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>-11.859685</td>\n",
       "      <td>0.020571</td>\n",
       "      <td>20.119292</td>\n",
       "      <td>0.023788</td>\n",
       "      <td>-9.390776</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>-13.472773</td>\n",
       "      <td>0.022126</td>\n",
       "      <td>0.083832</td>\n",
       "      <td>-21.645022</td>\n",
       "      <td>1.215470</td>\n",
       "      <td>-5.404140</td>\n",
       "      <td>0.022402</td>\n",
       "      <td>-0.324503</td>\n",
       "      <td>-2.475818</td>\n",
       "      <td>0.023296</td>\n",
       "      <td>0.835655</td>\n",
       "      <td>-0.059726</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.351598</td>\n",
       "      <td>0.865144</td>\n",
       "      <td>-17.539863</td>\n",
       "      <td>12.087614</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   td  code       F001      F002      F003      F004       F005      F006  \\\n",
       "0   1  A005   7.267364  0.004896  0.945559 -0.828748   0.641026 -0.038719   \n",
       "1   1  A006  -7.477904 -0.000128  1.089255  0.042335   7.640449  0.038965   \n",
       "2   1  A007   7.622525  0.001413  1.260723  0.001667  13.735577  0.025740   \n",
       "3   1  A011  51.693204  0.000000  6.967351  0.268144 -11.543311  0.143675   \n",
       "4   1  A012  -7.707446 -0.000763  1.201887  0.285988  21.070234 -0.006894   \n",
       "\n",
       "       F007      F008      F009      F010      F011      F012      F013  \\\n",
       "0  0.015282 -1.015634  1.136364  0.004044  0.011354  0.101754  71526.60   \n",
       "1  0.016616 -0.631765  1.010101 -0.002093  0.017224 -0.124314  66762.59   \n",
       "2  0.012530  6.140861  0.862069  0.001328  0.013585 -0.116173  43033.00   \n",
       "3  0.033834  0.401105  0.185529  0.006380  0.033150  1.671017   5573.01   \n",
       "4  0.017134  0.497051  0.833333  0.004365  0.016841 -0.350090  43167.36   \n",
       "\n",
       "       F014       F015      F016      F017      F018      F019       F020  \\\n",
       "0  0.100316  -4.768937  4.792733 -0.043790  0.060811  0.002848  38.238227   \n",
       "1  0.041121  -0.934142  3.893363  0.045088  0.027897 -0.002729   2.481333   \n",
       "2  0.018358  12.650914  2.044551  0.028468  0.126005 -0.001062   3.891949   \n",
       "3  0.096411   0.076096  0.131538  0.122475 -0.097907 -0.003738 -49.948921   \n",
       "4  0.000900   3.438244  7.199411  0.024039  0.107034 -0.000582 -11.859685   \n",
       "\n",
       "       F021       F022      F023       F024      F025      F026       F027  \\\n",
       "0  0.018440  -6.925412 -0.041526   6.302427  0.011433  0.001057   3.270022   \n",
       "1  0.019590  -1.043675  0.040733  -2.531807  0.008215 -0.001656  -1.306523   \n",
       "2  0.017248  24.251223  0.024875  -0.785996  0.018240  0.001696   9.377718   \n",
       "3  0.030242  -7.443115  0.135400  43.068155  0.034070 -0.006647  17.515292   \n",
       "4  0.020571  20.119292  0.023788  -9.390776  0.022019  0.004520 -13.472773   \n",
       "\n",
       "       F028      F029       F030      F031       F032      F033      F034  \\\n",
       "0 -0.011596  0.026144   5.016722  0.955414  12.749842  0.000141  0.137546   \n",
       "1  0.042740  0.014831  -2.244898  0.313152   1.775451  0.042377 -0.178182   \n",
       "2  0.022911  0.052338  13.965816  1.598579  -0.263783  0.017256  0.032633   \n",
       "3  0.088839  0.051290  56.189239  0.487805  -7.132306  0.091060  1.545997   \n",
       "4  0.022126  0.083832 -21.645022  1.215470  -5.404140  0.022402 -0.324503   \n",
       "\n",
       "        F035      F036      F037      F038      F039  F040      F041  \\\n",
       "0  48.333700 -0.043457 -1.567398  0.007646  0.002793   1.0  0.004724   \n",
       "1   3.555757  0.042450 -1.033058 -0.001463 -0.002713   2.0 -0.004431   \n",
       "2   4.309684  0.028468  7.648485  0.003168 -0.000951   6.0 -0.004544   \n",
       "3 -36.111240  0.118397  1.358087  0.037001 -0.004078   2.0  0.012924   \n",
       "4  -2.475818  0.023296  0.835655 -0.059726 -0.000538   5.0 -0.000045   \n",
       "\n",
       "       F042        F043      F044        F045       F046    target  \\\n",
       "0 -1.041667   13.357401  0.793424   11.347518   0.544470 -0.041401   \n",
       "1  2.040816  -14.464286  0.546866   -4.960317   3.914780 -0.010438   \n",
       "2  0.000000   13.052749  0.523903   -1.228115   9.910044 -0.042630   \n",
       "3 -7.142857  156.242771  1.050259  137.679277  -2.979930  0.109743   \n",
       "4  0.000000  -17.351598  0.865144  -17.539863  12.087614  0.058011   \n",
       "\n",
       "   binned_target  binary_target  \n",
       "0              0              0  \n",
       "1              2              0  \n",
       "2              0              0  \n",
       "3              4              1  \n",
       "4              4              1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dataset Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 최소한의 것들만 적용하고자 한다.\n",
    "- 3번 이하 등장하는 code (종목) 제거\n",
    "- EDA part5.12이 NaN preprocess 적용\n",
    "- train과 test에 code (종목)에 label encoding 적용\n",
    "- EMA를 활용한 F 파생변수 생성\n",
    "- code (종목) 기반의 aggregation 파생변수 생성m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3번 이하 등장하는 code (종목) 제거\n",
    "temp_dict = Counter(train_df['code'])\n",
    "outlier_codes = [k for k, v in set(temp_dict.items()) if v <= 3]\n",
    "train_df = train_df.loc[~train_df['code'].isin(outlier_codes)]\n",
    "\n",
    "# F feature만 추출\n",
    "F_cols = [col for col in train_df.columns if col.startswith('F')]\n",
    "\n",
    "train_df = preprocess_nan(train_df, F_cols)\n",
    "test_df = preprocess_nan(test_df, F_cols)\n",
    "\n",
    "# code (종목) 라벨 인코딩, group 통계 파생변수 생성을 위해서\n",
    "le = LabelEncoder().fit(pd.concat([train_df['code'], test_df['code']]))\n",
    "for df in [train_df, test_df]:\n",
    "    df['code_encoded'] = le.transform(df['code'])\n",
    "\n",
    "# EMA (Exponential Moving Average)를 각각의 F 피쳐에 적용하여 새로운 파생변수를 생성\n",
    "train_df = train_df.sort_values(by=['code', 'td']).reset_index(drop=True)\n",
    "test_df = test_df.sort_values(by=['code', 'td']).reset_index(drop=True)\n",
    "for feat_col in F_cols:\n",
    "    train_df[f'{feat_col}_EMA_3'] = EMA(train_df, feat_col, 3)\n",
    "    test_df[f'{feat_col}_EMA_3'] = EMA(test_df, feat_col, 3)\n",
    "\n",
    "# code (종목)별로 통계 기반 aggregation 파생변수 생성 (mean)\n",
    "train_df, test_df = code_agg(train_df, test_df, merge_columns=['code'], columns=F_cols, aggs=['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 구분\n",
    "target_cols = [col for col in train_df.columns if col in ['target', 'binned_target', 'binary_target']]\n",
    "remove_cols = ['td', 'code']\n",
    "remove_cols.append('code_encoded') # label encoding 피쳐는 사용하지 않는다.\n",
    "feat_cols = [col for col in train_df.columns if col not in target_cols+remove_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of NaNs in the Train Dataset: 0\n",
      "number of NaNs in the Test Dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# check if NaN exists\n",
    "print(\"number of NaNs in the Train Dataset: {}\".format(train_df[feat_cols].isnull().sum().sum()))\n",
    "print(\"number of NaNs in the Test Dataset: {}\".format(test_df[feat_cols].isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F001 F002 F003 F004 F005 F006 F007 F008 F009 F010 F011 F012 F013 F014 F015 F016 F017 F018 F019 F020 F021 F022 F023 F024 F025 F026 F027 F028 F029 F030 F031 F032 F033 F034 F035 F036 F037 F038 F039 F040 F041 F042 F043 F044 F045 F046 F001_EMA_3 F002_EMA_3 F003_EMA_3 F004_EMA_3 F005_EMA_3 F006_EMA_3 F007_EMA_3 F008_EMA_3 F009_EMA_3 F010_EMA_3 F011_EMA_3 F012_EMA_3 F013_EMA_3 F014_EMA_3 F015_EMA_3 F016_EMA_3 F017_EMA_3 F018_EMA_3 F019_EMA_3 F020_EMA_3 F021_EMA_3 F022_EMA_3 F023_EMA_3 F024_EMA_3 F025_EMA_3 F026_EMA_3 F027_EMA_3 F028_EMA_3 F029_EMA_3 F030_EMA_3 F031_EMA_3 F032_EMA_3 F033_EMA_3 F034_EMA_3 F035_EMA_3 F036_EMA_3 F037_EMA_3 F038_EMA_3 F039_EMA_3 F040_EMA_3 F041_EMA_3 F042_EMA_3 F043_EMA_3 F044_EMA_3 F045_EMA_3 F046_EMA_3 code_mean_F001 code_mean_F002 code_mean_F003 code_mean_F004 code_mean_F005 code_mean_F006 code_mean_F007 code_mean_F008 code_mean_F009 code_mean_F010 code_mean_F011 code_mean_F012 code_mean_F013 code_mean_F014 code_mean_F015 code_mean_F016 code_mean_F017 code_mean_F018 code_mean_F019 code_mean_F020 code_mean_F021 code_mean_F022 code_mean_F023 code_mean_F024 code_mean_F025 code_mean_F026 code_mean_F027 code_mean_F028 code_mean_F029 code_mean_F030 code_mean_F031 code_mean_F032 code_mean_F033 code_mean_F034 code_mean_F035 code_mean_F036 code_mean_F037 code_mean_F038 code_mean_F039 code_mean_F040 code_mean_F041 code_mean_F042 code_mean_F043 code_mean_F044 code_mean_F045 code_mean_F046 \n",
      "\n",
      "total features used for training: 138\n"
     ]
    }
   ],
   "source": [
    "# 학습에 사용하는 feature 칼럼들\n",
    "for col in feat_cols:\n",
    "    print(col, end=' ')\n",
    "print(\"\\n\\ntotal features used for training: {}\".format(len(feat_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 tree계열과 mlp 모델 학습을 위한 최종 데이터셋 (train, validation split + feature normalizing)\n",
    "dataset_dict = make_dict(train_df, test_df, feat_cols, 'binary_target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Validation Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple Random Hold-out-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![111111](https://user-images.githubusercontent.com/40786348/73930754-6c1c6900-491a-11ea-8e6e-bf38c6ba9e02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순하게 데이터셋의 일부를 validation set으로 활용하는 방법이다. 시계열을 무시하지만 처음 모델링을 시작하기 전에 baseline으로 잡기 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Last Time Hold-Out-Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![valid1](https://user-images.githubusercontent.com/40786348/73640980-97048400-46b2-11ea-8f81-b0d606dd916e.png)\n",
    "출처: Predicting the direction of stock market prices using random forest (https://arxiv.org/abs/1605.00003v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T02:50:27.084965Z",
     "start_time": "2020-02-02T02:50:27.050306Z"
    }
   },
   "source": [
    "시계열 특성을 고려했을시 Validation Split 방법 중에서 가장 간단한 방법이다.\n",
    "<br>\n",
    "train set을 시간으로 정렬하여 마지막 부분을 떼어내 validation set으로 활용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sliding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![validation](https://user-images.githubusercontent.com/40786348/73620023-58030e00-4673-11ea-8f95-e51503d3174f.png)\n",
    "출처: Predicting the direction of stock market prices using random forest (https://arxiv.org/abs/1605.00003v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 방법으로 보다 더 정확하게 test set을 예측할 수 있을 것이다.\n",
    "<br>\n",
    "더 많은 모델을 생성하여 다양한 시간 단위를 기반으로 validation 한다면 test set 예측 성능이 좀 더 robust해질 것이다.\n",
    "<br>\n",
    "물론 정확도와 모델 학습 시간은 trade-off 관계에 있으니 이 부분을 잘 고려하여 모델링을 한다면 좋으리라 생각한다.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Tree based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stock](https://user-images.githubusercontent.com/40786348/73641895-0e86e300-46b4-11ea-9b36-f651a549f28f.png)\n",
    "\n",
    "[paper link](https://arxiv.org/abs/1605.00003v1)\n",
    "<br>\n",
    "위 논문에 의하면 연속값을 예측하는 regression 문제보다, 분류 문제로 접근했을 시에 더 나은 performance를 보였기 때문에 필자도 **이진 분류 문제**로 접근하고자 한다.\n",
    "모델에서 나온 예측 결과는 주식 시장에서 투자를 하는 의사 결정권자를 support 할 수 있기를 기대한다.\n",
    "<br>\n",
    "<br>\n",
    "위 논문에서는 예측을 위한 지표로서 많이 활용되는 Relative Strength Index, Stochastic Oscillator와 같은 \n",
    "<br>\n",
    "Techinical Indicators들을 exponential smoothing을 통해 전처리를 하였고 Random Forest 모델을 활용하여 예측을 하였다.\n",
    "<br>\n",
    "논문에서 사용한 Random Forest는 Bootstrapping을 통한 오버피팅을 방지한다는 장점이 있지만 학습이 오래걸리기 때문에 사용하지 않았다.\n",
    "<br>\n",
    "대신 다수의 경진대회에서 비교적 빠른 시간에 높은 성능을 자랑하는 **[Light GBM 모델](https://lightgbm.readthedocs.io/en/latest/)**을 사용하여 학습을 진행하였다.\n",
    "또한 다수의 피쳐들이 비식별화되어 있기 때문에, validation 성능을 기준으로 파생 변수를 생성하여 예측 성능을 높이고자 했다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light GBM parameters\n",
    "lgb_params = {\n",
    "                'objective':'binary',\n",
    "                'boosting_type':'gbdt',\n",
    "                'metric':'auc',\n",
    "                'n_jobs':-1,\n",
    "                'learning_rate':0.01,\n",
    "                'num_leaves': 2**8,\n",
    "                'max_depth':-1,\n",
    "                'tree_learner':'serial',\n",
    "                'colsample_bytree': 0.7,\n",
    "                'subsample_freq':1,\n",
    "                'subsample':0.7,\n",
    "                'n_estimators':3000,\n",
    "                'max_bin':255,\n",
    "                'verbose':-1,\n",
    "                'seed': 42,\n",
    "                'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 살펴본 검증 전략들을 tree 기반 모델에 적용시켜보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Simple Random Hold-out-set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df[feat_cols], train_df[target_cols[2]], test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "tr_data = lgb.Dataset(X_train, label=y_train)\n",
    "vl_data = lgb.Dataset(X_valid, label=y_valid) \n",
    "\n",
    "clf = lgb.train(\n",
    "    lgb_params,\n",
    "    tr_data,\n",
    "    valid_sets = [tr_data, vl_data],\n",
    "    verbose_eval = 100 ,\n",
    ")   \n",
    "\n",
    "preds = clf.predict(X_valid)\n",
    "print(\"\\naccuracy score: {:.4f}\".format(accuracy_score(y_valid, to_binary(preds))))\n",
    "print(\"roc_auc score: {:.4f}\".format(roc_auc_score(y_valid, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "56% 정도의 정확도를 달성한다.\n",
    "<br>\n",
    "하지만 위와 같은 validation 방법은 옳지 못하다. 우리가 예측하고자 하는 데이터는 미래의 특정 기간이다.\n",
    "<br>\n",
    "따라서 이 특정 기간을 대변해 줄 수 있는 validation set을 잘 고르는 것이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Last Time Hold-Out-Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 1: train (1 <= td <= 172) valid (172 < td <= 206)\n",
    "preds = make_predictions(dataset_dict, train_df, feat_cols, lgb_params, valid_type='hold_out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트리 모델의 장점은 feature importance를 시각화함으로써 어떤 피쳐가 모델 예측에 있어서 중요하게 작용했는지 눈으로 파악할 수 있다는 점이다.\n",
    "<br>\n",
    "추후 파생변수 생성을 통하여 tree 기반의 모델링을 수행할 경우 이 점을 참고하여 feature engineering을 진행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Sliding Window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확한 구현은 아니지만, 시간 단위가 비식별화 되어있어 나누기가 모호하기 때문에 다음과 같이 진행한다.\n",
    "# dataset 1: train (1 <= td <= 172) valid (172 < td <= 206)\n",
    "# dataset 2: train (1 <= td <= 206) valid (206 < td <= 240)\n",
    "# dataset 3: train (1 <= td <= 240) valid (240 < td <= 276)\n",
    "preds = make_predictions(dataset_dict, train_df, feat_cols, lgb_params, valid_type='sliding_window')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline이기 때문에 높은 정확도를 달성하는데는 무리가 있다. 더 높은 정확도를 위해서는 정교한 hyper parameter 튜닝과 파생변수 생성이 요구될 것으로 보인다.\n",
    "<br>\n",
    "지금부터는 딥러닝 기반의 모델링을 수행해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. MLP based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 지금부터는 뉴럴넷 기반의 모델링을 진행해보고자 한다.\n",
    "<br>\n",
    "앞선 EDA에서 살펴봤듯이, 독립변수와 종속변수 간에 상관관계가 전혀 존재하지 않는 매우 어려운 문제이다.\n",
    "<br>\n",
    "따라서 다수의 acitvation 함수 쌓아 학습을 한다면 더 나은 예측을 할 수 있으리라 생각한다.\n",
    "<br>\n",
    "첫 번째 모델은, **MLP(multi-layer-perceptron)** 기반의 모델이며, 두 번째 모델은 **RNN** 기반의 모델링이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if using cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_cuda = True if device.type == 'cuda' else False\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output path \n",
    "output_dir = Path('./', 'output')\n",
    "output_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train setting (hyper parameters)\n",
    "valid_type = 'sliding_window' # in ['hold_out', 'sliding_window']\n",
    "# 설명을 덧붙이자면, hold_out 방법은 어떤 피쳐가 좋은지 실험해보고자 할 때, 짧은 시간 안에 수행할 수 있기에 이점이 있는 반면에\n",
    "# sliding_window 방법은 본격적으로 학습을 진행하고자 할 때 사용하도록 한다.\n",
    "num_epochs = 120\n",
    "verbose_epoch = 20\n",
    "lr = 0.00025\n",
    "batch_size = 1024\n",
    "num_classes = 1 # 이진 분류\n",
    "num_feats = len(feat_cols)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation 종류에 따라 나눈다 (hold_out, sliding_window 두 종류)\n",
    "if valid_type == 'hold_out':\n",
    "    print(f\"training starts (hold-out)\")\n",
    "    \n",
    "    model = build_model(device, 'MLP', num_classes, num_feats)\n",
    "    optimizer = AdamW(model.parameters(), lr, weight_decay=0.000025)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "\n",
    "    X_train = dataset_dict['X_train3']\n",
    "    y_train = dataset_dict['y_train3']\n",
    "    X_valid = dataset_dict['X_valid3']\n",
    "    y_valid = dataset_dict['y_valid3']\n",
    "    \n",
    "    train_loader = build_dataloader(X_train, y_train, batch_size, shuffle=True)\n",
    "    valid_loader = build_dataloader(X_valid, y_valid, batch_size, shuffle=False)\n",
    "    train_mlp_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, use_cuda, verbose_epoch)\n",
    "    \n",
    "# total prediction (using 3 models)\n",
    "elif valid_type == 'sliding_window':\n",
    "    window_num = 3\n",
    "    for num in range(1, window_num+1):    \n",
    "        \n",
    "        print(f\"num {num} dataset training starts (sliding_window)\")\n",
    "        '''\n",
    "        dataset 1: train (1 <= td <= 172) valid (172 < td <= 206)\n",
    "        dataset 2: train (1 <= td <= 206) valid (206 < td <= 240)\n",
    "        dataset 3: train (1 <= td <= 240) valid (240 < td <= 276)\n",
    "        '''\n",
    "        model = build_model(device, 'MLP', num_classes, num_feats)\n",
    "        optimizer = AdamW(model.parameters(), lr, weight_decay=0.000025)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10)\n",
    "\n",
    "        X_train = dataset_dict[f'X_train{num}']\n",
    "        y_train = dataset_dict[f'y_train{num}']\n",
    "        X_valid = dataset_dict[f'X_valid{num}']\n",
    "        y_valid = dataset_dict[f'y_valid{num}']\n",
    "        train_loader = build_dataloader(X_train, y_train, batch_size, shuffle=True)\n",
    "        valid_loader = build_dataloader(X_valid, y_valid, batch_size, shuffle=False)\n",
    "        path = f'best_model_{num}.pt'\n",
    "        train_mlp_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, use_cuda, verbose_epoch, path)\n",
    "        del model; gc.collect()\n",
    "        print(\"#\"*150)\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 validation의 정확도가 시계열적 요소를 완전하게 반영하기는 힘들기 때문에 test set에서의 성능을 보장하지는 않을 것이라 예상된다.\n",
    "<br>\n",
    "딥러닝은 **weight 초기값(initialization)** 에 따라서도 결과가 달라지기 때문에, 다양한 seed값을 기반으로 학습한다면 test set에서의 성능을 좀 더 robust하게 만들어줄 수 있을 것으로 기대된다.\n",
    "<br>\n",
    "하지만 그만큼 학습이 오래걸린다는 단점이 있기 때문에, 학습 시간을 고려하여 사용하는 것이 좋으리라 생각한다. \n",
    "<br>\n",
    "따라서 서로 다른 code (종목) 간의 특성까지 고려하여, 학습에 반영을 하든지 아니면 최종 모델 선택에 있어서 반영할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP inference [hold_out or sliding_window]\n",
    "if valid_type == 'hold_out':\n",
    "\n",
    "    test_loader = build_dataloader(dataset_dict['x_test'], Y=None, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model_path = os.listdir('../working/output')[0]\n",
    "    model = build_model(device, 'MLP', num_classes, num_feats)\n",
    "    model.load_state_dict(torch.load(os.path.join('../working/output/', model_path)))\n",
    "    model.to(device)\n",
    "    total_preds = mlp_inference(model, test_loader, batch_size, use_cuda)\n",
    "    total_preds = np.where(total_preds >= 0.5, 1, 0)\n",
    "    \n",
    "elif valid_type == 'sliding_window':\n",
    "    \n",
    "    model_list = os.listdir('../working/output')\n",
    "    total_preds = []\n",
    "    window_num = 3\n",
    "    \n",
    "    for i in range(window_num):\n",
    "        \n",
    "        batch_size = 1024\n",
    "        test_loader = build_dataloader(dataset_dict['x_test'], Y=None, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = build_model(device, 'MLP', num_classes, num_feats)\n",
    "        model_path = model_list[i]\n",
    "        model.load_state_dict(torch.load(os.path.join('../working/output/', model_path)))\n",
    "        model.to(device)\n",
    "\n",
    "        test_preds = mlp_inference(model, test_loader, batch_size, use_cuda)\n",
    "        total_preds.append(test_preds)\n",
    "        \n",
    "    # logit 단에서 모델 세 개의 결과값을 평균 (3개의 window 기반으로 검증된)\n",
    "    total_preds = np.mean(total_preds, axis=0)\n",
    "    total_preds = np.where(total_preds >= 0.5, 1, 0)\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['prediction'] = total_preds\n",
    "submission = test_df[['td', 'code', 'prediction']].set_index(['td', 'code'])\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set 예측값의 분포가 대략 반반으로 잘 나온것으로 확인된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. RNN based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![haha](https://user-images.githubusercontent.com/40786348/73935061-15675d00-4923-11ea-98a4-74cd8aa81e22.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지는 트리 기반의 모델과 MLP 기반의 모델링을 살펴봤다면, 이번 section에서는 RNN을 살펴보고자 한다.\n",
    "<br>\n",
    "RNN은 회귀 문제로 접근하여 위 이미지의 가장 우측에 해당하는 many-to-many 구조의 RNN을 채택하였다. \n",
    "<br>\n",
    "회귀 문제로 접근했을 때의 이점은 예측 결과를 시각화할 수 있다는 점이다.\n",
    "<br>\n",
    "이를 통해 학습이 정상적으로 진행되고 있는지 확인할 수 있다. 잘 설계된 모델 구조와 잘 생성된 피쳐들은 회귀/분류 문제 상관없이 성능이 좋게 나오기 마련이다.\n",
    "<br>\n",
    "<br>\n",
    "또한 오직 하나의 종목을 기반으로 학습하는 코드를 작성하고자 한다. 안타깝게도 제출 기한이 있어 모든 종목을 활용하여 학습하는 완성된 코드를 작성하지는 못했다.\n",
    "<br>\n",
    "아래 코드를 통해 학습 진행 과정에 따라 예측값이 어떤식으로 변화하는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40]  train_loss: 0.01946\n",
      "Epoch [40/40]  train_loss: 0.01635\n",
      "\n",
      "Best epoch: 40  Best Loss: 0.01635\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "target",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116
         ],
         "y": [
          -0.011061946902654829,
          0.02460850111856816,
          -0.0021834061135370675,
          0.006564551422319376,
          -0.01521739130434785,
          0.019867549668874274,
          0.015151515151515138,
          0.019189765458422103,
          0.0020920502092049986,
          0.0041753653444676075,
          -0.037422037422037424,
          -0.025917926565874768,
          0.05764966740576494,
          -0.018867924528301886,
          -0.05982905982905984,
          0.05000000000000005,
          0.06060606060606055,
          0.04693877551020398,
          0.0038986354775829572,
          0.01941747572815533,
          0.0647619047619048,
          -0.04472271914132375,
          -0.011235955056179804,
          -0.003787878787878785,
          0,
          0.0323193916349811,
          0.04051565377532218,
          -0.0035398230088495852,
          0.014209591474245054,
          -0.03327495621716292,
          -0.003623188405797117,
          0.05818181818181811,
          0.012027491408934663,
          -0.02886247877758918,
          0,
          0.06643356643356646,
          0.003278688524590123,
          -0.004901960784313708,
          -0.01970443349753692,
          0.01842546063651596,
          -0.06414473684210531,
          0.012302284710017595,
          0.013888888888888841,
          -0.056506849315068435,
          0.05444646098003636,
          -0.02237521514629948,
          -0.02640845070422537,
          -0.06329113924050632,
          0.02509652509652516,
          -0.03766478342749524,
          0.03718199608610573,
          0.007547169811320753,
          -0.16104868913857673,
          0.03125,
          -0.03030303030303028,
          0.0245535714285714,
          -0.04793028322440085,
          0.04347826086956519,
          0.030701754385964893,
          -0.017021276595744702,
          0.03463203463203457,
          -0.006276150627615107,
          -0.05684210526315792,
          0.01116071428571419,
          0.13907284768211925,
          -0.023255813953488413,
          -0.009920634920634884,
          -0.040080160320641316,
          0.014613778705636847,
          -0.06378600823045266,
          -0.00219780219780219,
          0.0022026431718060735,
          -0.08791208791208792,
          -0.04337349397590362,
          0.05037783375314864,
          -0.014388489208633115,
          -0.03649635036496346,
          0.05050505050505062,
          -0.043269230769230727,
          0.025125628140703515,
          0.0269607843137254,
          -0.04534606205250602,
          0,
          -0.0050000000000000044,
          -0.12060301507537685,
          0.0028571428571428914,
          -0.03703703703703709,
          0.047337278106508895,
          0.028248587570621538,
          0.008241758241758212,
          -0.019073569482288773,
          0.013888888888888841,
          -0.03013698630136985,
          -0.07627118644067797,
          -0.05504587155963303,
          -0.07766990291262132,
          0.0736842105263158,
          0.019607843137254832,
          0.02564102564102555,
          -0.018750000000000044,
          -0.07006369426751591,
          -0.0821917808219178,
          0.033582089552238736,
          -0.02166064981949456,
          -0.05166051660516602,
          -0.03891050583657585,
          0.03921568627450989,
          0.02641509433962264,
          0.022058823529411686,
          0.010791366906474751,
          0.04982206405693956,
          -0.016949152542372836,
          -0.0482758620689655,
          -0.025362318840579712,
          -0.01941747572815533,
          -0.035031847133757954,
          -0.07590759075907594
         ]
        },
        {
         "name": "predicted",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116
         ],
         "y": [
          0.02140102908015251,
          0.032315682619810104,
          0.01957763358950615,
          0.008760549128055573,
          0.010923955589532852,
          0.004112798720598221,
          0.0004216805100440979,
          0.0063559189438819885,
          0.0008938498795032501,
          0.0012129954993724823,
          -0.01924215629696846,
          -0.013410322368144989,
          0.027767185121774673,
          0.017731543630361557,
          0.01294325664639473,
          0.03209080174565315,
          0.027860958129167557,
          0.00980369746685028,
          -0.0016635991632938385,
          0.0007901228964328766,
          0.009920243173837662,
          -0.005702599883079529,
          -0.00314321368932724,
          0.007174678146839142,
          0.008603114634752274,
          0.011149588972330093,
          0.006905313581228256,
          0.004278726875782013,
          0.00672319158911705,
          0.004549898207187653,
          0.004784677177667618,
          0.008515585213899612,
          0.0013536140322685242,
          -0.0062105171382427216,
          0.013418491929769516,
          0.011858668178319931,
          -0.008225880563259125,
          -0.01312490925192833,
          -0.006474275141954422,
          -0.006067298352718353,
          -0.00985894724726677,
          0.006143864244222641,
          0.008284751325845718,
          -0.011633768677711487,
          -0.010459952056407928,
          -0.017991121858358383,
          -0.020577682182192802,
          -0.01200353354215622,
          -0.005761981010437012,
          -0.006762325763702393,
          -0.01911322772502899,
          -0.030412109568715096,
          -0.038705725222826004,
          0.015234772115945816,
          0.011965315788984299,
          0.011230524629354477,
          0.0035039186477661133,
          0.0198531411588192,
          0.011473488062620163,
          -0.003981247544288635,
          -0.006136994808912277,
          -0.015488695353269577,
          0.005506694316864014,
          0.02570648118853569,
          0.024532083421945572,
          -0.010779760777950287,
          -0.02157203108072281,
          -0.021263808012008667,
          -0.015952911227941513,
          -0.017753083258867264,
          -0.020502790808677673,
          -0.01683701202273369,
          -0.013889987021684647,
          0.004042569547891617,
          0.01091691106557846,
          0.0017959997057914734,
          -0.006964489817619324,
          -0.005452774465084076,
          -0.00930919498205185,
          -0.011092554777860641,
          -0.018206514418125153,
          -0.027248473837971687,
          -0.011725474148988724,
          -0.015175636857748032,
          -0.022871922701597214,
          -0.010188471525907516,
          -0.00420108437538147,
          -0.004896901547908783,
          -0.004313454031944275,
          -0.01770760864019394,
          -0.0294271819293499,
          -0.03369952738285065,
          -0.03909799084067345,
          -0.03456861898303032,
          -0.02464432641863823,
          -0.0062443166971206665,
          0.017490189522504807,
          0.0172823928296566,
          -0.007382631301879883,
          -0.019795645028352737,
          -0.031945016235113144,
          -0.027947569265961647,
          -0.02491707354784012,
          -0.021604154258966446,
          -0.02040964551270008,
          0.002605017274618149,
          0.018572811037302017,
          0.02622314915060997,
          0.016619566828012466,
          0.0033815689384937286,
          -0.006408855319023132,
          -0.015905845910310745,
          -0.02479640394449234,
          -0.0175652876496315,
          -0.019118253141641617,
          -0.04769504815340042,
          -0.04908159002661705
         ]
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "code: A507"
        },
        "xaxis": {
         "title": {
          "text": "Time"
         }
        },
        "yaxis": {
         "title": {
          "text": "Earning Ratio (target)"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"131a439a-f91f-4bc4-a98f-6e2cff336163\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"131a439a-f91f-4bc4-a98f-6e2cff336163\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '131a439a-f91f-4bc4-a98f-6e2cff336163',\n",
       "                        [{\"name\": \"target\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], \"y\": [-0.011061946902654829, 0.02460850111856816, -0.0021834061135370675, 0.006564551422319376, -0.01521739130434785, 0.019867549668874274, 0.015151515151515138, 0.019189765458422103, 0.0020920502092049986, 0.0041753653444676075, -0.037422037422037424, -0.025917926565874768, 0.05764966740576494, -0.018867924528301886, -0.05982905982905984, 0.05000000000000005, 0.06060606060606055, 0.04693877551020398, 0.0038986354775829572, 0.01941747572815533, 0.0647619047619048, -0.04472271914132375, -0.011235955056179804, -0.003787878787878785, 0.0, 0.0323193916349811, 0.04051565377532218, -0.0035398230088495852, 0.014209591474245054, -0.03327495621716292, -0.003623188405797117, 0.05818181818181811, 0.012027491408934663, -0.02886247877758918, 0.0, 0.06643356643356646, 0.003278688524590123, -0.004901960784313708, -0.01970443349753692, 0.01842546063651596, -0.06414473684210531, 0.012302284710017595, 0.013888888888888841, -0.056506849315068435, 0.05444646098003636, -0.02237521514629948, -0.02640845070422537, -0.06329113924050632, 0.02509652509652516, -0.03766478342749524, 0.03718199608610573, 0.007547169811320753, -0.16104868913857673, 0.03125, -0.03030303030303028, 0.0245535714285714, -0.04793028322440085, 0.04347826086956519, 0.030701754385964893, -0.017021276595744702, 0.03463203463203457, -0.006276150627615107, -0.05684210526315792, 0.01116071428571419, 0.13907284768211925, -0.023255813953488413, -0.009920634920634884, -0.040080160320641316, 0.014613778705636847, -0.06378600823045266, -0.00219780219780219, 0.0022026431718060735, -0.08791208791208792, -0.04337349397590362, 0.05037783375314864, -0.014388489208633115, -0.03649635036496346, 0.05050505050505062, -0.043269230769230727, 0.025125628140703515, 0.0269607843137254, -0.04534606205250602, 0.0, -0.0050000000000000044, -0.12060301507537685, 0.0028571428571428914, -0.03703703703703709, 0.047337278106508895, 0.028248587570621538, 0.008241758241758212, -0.019073569482288773, 0.013888888888888841, -0.03013698630136985, -0.07627118644067797, -0.05504587155963303, -0.07766990291262132, 0.0736842105263158, 0.019607843137254832, 0.02564102564102555, -0.018750000000000044, -0.07006369426751591, -0.0821917808219178, 0.033582089552238736, -0.02166064981949456, -0.05166051660516602, -0.03891050583657585, 0.03921568627450989, 0.02641509433962264, 0.022058823529411686, 0.010791366906474751, 0.04982206405693956, -0.016949152542372836, -0.0482758620689655, -0.025362318840579712, -0.01941747572815533, -0.035031847133757954, -0.07590759075907594]}, {\"name\": \"predicted\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], \"y\": [0.02140102908015251, 0.032315682619810104, 0.01957763358950615, 0.008760549128055573, 0.010923955589532852, 0.004112798720598221, 0.0004216805100440979, 0.0063559189438819885, 0.0008938498795032501, 0.0012129954993724823, -0.01924215629696846, -0.013410322368144989, 0.027767185121774673, 0.017731543630361557, 0.01294325664639473, 0.03209080174565315, 0.027860958129167557, 0.00980369746685028, -0.0016635991632938385, 0.0007901228964328766, 0.009920243173837662, -0.005702599883079529, -0.00314321368932724, 0.007174678146839142, 0.008603114634752274, 0.011149588972330093, 0.006905313581228256, 0.004278726875782013, 0.00672319158911705, 0.004549898207187653, 0.004784677177667618, 0.008515585213899612, 0.0013536140322685242, -0.0062105171382427216, 0.013418491929769516, 0.011858668178319931, -0.008225880563259125, -0.01312490925192833, -0.006474275141954422, -0.006067298352718353, -0.00985894724726677, 0.006143864244222641, 0.008284751325845718, -0.011633768677711487, -0.010459952056407928, -0.017991121858358383, -0.020577682182192802, -0.01200353354215622, -0.005761981010437012, -0.006762325763702393, -0.01911322772502899, -0.030412109568715096, -0.038705725222826004, 0.015234772115945816, 0.011965315788984299, 0.011230524629354477, 0.0035039186477661133, 0.0198531411588192, 0.011473488062620163, -0.003981247544288635, -0.006136994808912277, -0.015488695353269577, 0.005506694316864014, 0.02570648118853569, 0.024532083421945572, -0.010779760777950287, -0.02157203108072281, -0.021263808012008667, -0.015952911227941513, -0.017753083258867264, -0.020502790808677673, -0.01683701202273369, -0.013889987021684647, 0.004042569547891617, 0.01091691106557846, 0.0017959997057914734, -0.006964489817619324, -0.005452774465084076, -0.00930919498205185, -0.011092554777860641, -0.018206514418125153, -0.027248473837971687, -0.011725474148988724, -0.015175636857748032, -0.022871922701597214, -0.010188471525907516, -0.00420108437538147, -0.004896901547908783, -0.004313454031944275, -0.01770760864019394, -0.0294271819293499, -0.03369952738285065, -0.03909799084067345, -0.03456861898303032, -0.02464432641863823, -0.0062443166971206665, 0.017490189522504807, 0.0172823928296566, -0.007382631301879883, -0.019795645028352737, -0.031945016235113144, -0.027947569265961647, -0.02491707354784012, -0.021604154258966446, -0.02040964551270008, 0.002605017274618149, 0.018572811037302017, 0.02622314915060997, 0.016619566828012466, 0.0033815689384937286, -0.006408855319023132, -0.015905845910310745, -0.02479640394449234, -0.0175652876496315, -0.019118253141641617, -0.04769504815340042, -0.04908159002661705]}],\n",
       "                        {\"legend\": {\"orientation\": \"h\"}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"code: A507\"}, \"xaxis\": {\"title\": {\"text\": \"Time\"}}, \"yaxis\": {\"title\": {\"text\": \"Earning Ratio (target)\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('131a439a-f91f-4bc4-a98f-6e2cff336163');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code 'A507' 학습 (40 epoch)\n",
    "lstm_train_visualize(train_df, 'A507', feat_cols, num_epochs=40, seq_len=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100]  train_loss: 0.02065\n",
      "Epoch [40/100]  train_loss: 0.01725\n",
      "Epoch [60/100]  train_loss: 0.01413\n",
      "Epoch [80/100]  train_loss: 0.01091\n",
      "Epoch [100/100]  train_loss: 0.00782\n",
      "\n",
      "Best epoch: 100  Best Loss: 0.00782\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "target",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116
         ],
         "y": [
          -0.011061946902654829,
          0.02460850111856816,
          -0.0021834061135370675,
          0.006564551422319376,
          -0.01521739130434785,
          0.019867549668874274,
          0.015151515151515138,
          0.019189765458422103,
          0.0020920502092049986,
          0.0041753653444676075,
          -0.037422037422037424,
          -0.025917926565874768,
          0.05764966740576494,
          -0.018867924528301886,
          -0.05982905982905984,
          0.05000000000000005,
          0.06060606060606055,
          0.04693877551020398,
          0.0038986354775829572,
          0.01941747572815533,
          0.0647619047619048,
          -0.04472271914132375,
          -0.011235955056179804,
          -0.003787878787878785,
          0,
          0.0323193916349811,
          0.04051565377532218,
          -0.0035398230088495852,
          0.014209591474245054,
          -0.03327495621716292,
          -0.003623188405797117,
          0.05818181818181811,
          0.012027491408934663,
          -0.02886247877758918,
          0,
          0.06643356643356646,
          0.003278688524590123,
          -0.004901960784313708,
          -0.01970443349753692,
          0.01842546063651596,
          -0.06414473684210531,
          0.012302284710017595,
          0.013888888888888841,
          -0.056506849315068435,
          0.05444646098003636,
          -0.02237521514629948,
          -0.02640845070422537,
          -0.06329113924050632,
          0.02509652509652516,
          -0.03766478342749524,
          0.03718199608610573,
          0.007547169811320753,
          -0.16104868913857673,
          0.03125,
          -0.03030303030303028,
          0.0245535714285714,
          -0.04793028322440085,
          0.04347826086956519,
          0.030701754385964893,
          -0.017021276595744702,
          0.03463203463203457,
          -0.006276150627615107,
          -0.05684210526315792,
          0.01116071428571419,
          0.13907284768211925,
          -0.023255813953488413,
          -0.009920634920634884,
          -0.040080160320641316,
          0.014613778705636847,
          -0.06378600823045266,
          -0.00219780219780219,
          0.0022026431718060735,
          -0.08791208791208792,
          -0.04337349397590362,
          0.05037783375314864,
          -0.014388489208633115,
          -0.03649635036496346,
          0.05050505050505062,
          -0.043269230769230727,
          0.025125628140703515,
          0.0269607843137254,
          -0.04534606205250602,
          0,
          -0.0050000000000000044,
          -0.12060301507537685,
          0.0028571428571428914,
          -0.03703703703703709,
          0.047337278106508895,
          0.028248587570621538,
          0.008241758241758212,
          -0.019073569482288773,
          0.013888888888888841,
          -0.03013698630136985,
          -0.07627118644067797,
          -0.05504587155963303,
          -0.07766990291262132,
          0.0736842105263158,
          0.019607843137254832,
          0.02564102564102555,
          -0.018750000000000044,
          -0.07006369426751591,
          -0.0821917808219178,
          0.033582089552238736,
          -0.02166064981949456,
          -0.05166051660516602,
          -0.03891050583657585,
          0.03921568627450989,
          0.02641509433962264,
          0.022058823529411686,
          0.010791366906474751,
          0.04982206405693956,
          -0.016949152542372836,
          -0.0482758620689655,
          -0.025362318840579712,
          -0.01941747572815533,
          -0.035031847133757954,
          -0.07590759075907594
         ]
        },
        {
         "name": "predicted",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116
         ],
         "y": [
          0.02292887680232525,
          0.015502911061048508,
          -0.0020493417978286743,
          0.0022344067692756653,
          0.016725193709135056,
          0.023659957572817802,
          0.0089472196996212,
          -0.00731629878282547,
          -0.005757838487625122,
          0.0062415711581707,
          -0.04082886129617691,
          -0.02940763533115387,
          0.04627835750579834,
          -0.02113967016339302,
          0.000980272889137268,
          0.06999098509550095,
          0.058552928268909454,
          0.021148324012756348,
          0.005362033843994141,
          0.006622225046157837,
          0.013908760622143745,
          -0.016760218888521194,
          -0.01862408220767975,
          0.009186377748847008,
          0.014417935162782669,
          0.03650720417499542,
          0.025733746588230133,
          -0.01461954414844513,
          -0.0014907419681549072,
          0.004046536982059479,
          0.011837923899292946,
          0.030625708401203156,
          0.007792174816131592,
          -0.018526457250118256,
          0.03247945383191109,
          0.04455384984612465,
          -0.013219133019447327,
          -0.025113597512245178,
          -0.003961704671382904,
          -0.0005805082619190216,
          -0.03275252878665924,
          -0.0006485618650913239,
          0.006605394184589386,
          -0.015378646552562714,
          0.009183619171380997,
          -0.023524239659309387,
          -0.039497703313827515,
          -0.02874165028333664,
          0.008943364024162292,
          -0.003258034586906433,
          -0.011723417788743973,
          -0.03641423583030701,
          -0.09914238750934601,
          0.028338395059108734,
          -0.017804346978664398,
          -0.0043035708367824554,
          -0.007910545915365219,
          0.03333890065550804,
          0.03817000985145569,
          -0.0009491071105003357,
          0.008885174989700317,
          -0.01555664837360382,
          -0.029575206339359283,
          0.041935428977012634,
          0.08291533589363098,
          -0.015450645238161087,
          -0.029708385467529297,
          -0.02456345409154892,
          -0.014692924916744232,
          -0.025435395538806915,
          -0.02010243386030197,
          -0.02216877043247223,
          -0.05757050961256027,
          -0.010539084672927856,
          0.024228200316429138,
          -0.00811149924993515,
          -0.013917934149503708,
          0.019829444587230682,
          -0.005587227642536163,
          0.011068658903241158,
          0.0068425461649894714,
          -0.01801116392016411,
          -0.025069206953048706,
          -0.03234192728996277,
          -0.049574702978134155,
          -0.014775339514017105,
          0.0019017122685909271,
          0.012604568153619766,
          0.0009542033076286316,
          -0.014436796307563782,
          -0.020294751971960068,
          -0.030728697776794434,
          -0.04077797383069992,
          -0.055154792964458466,
          -0.04884099215269089,
          -0.020771730691194534,
          0.04597574844956398,
          0.0383770577609539,
          0.006885487586259842,
          -0.03078571707010269,
          -0.06971979141235352,
          -0.047212086617946625,
          0.003650754690170288,
          -0.0232388973236084,
          -0.048285096883773804,
          -0.017272643744945526,
          0.019418664276599884,
          0.033458881080150604,
          0.0312894806265831,
          0.020411891862750053,
          0.0098477303981781,
          -0.004096522927284241,
          -0.023632779717445374,
          -0.024489954113960266,
          -0.034578241407871246,
          -0.0674264058470726,
          -0.07547461986541748
         ]
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "code: A507"
        },
        "xaxis": {
         "title": {
          "text": "Time"
         }
        },
        "yaxis": {
         "title": {
          "text": "Earning Ratio (target)"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"81998772-9bf4-401f-a6e8-ba7920dd08af\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"81998772-9bf4-401f-a6e8-ba7920dd08af\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '81998772-9bf4-401f-a6e8-ba7920dd08af',\n",
       "                        [{\"name\": \"target\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], \"y\": [-0.011061946902654829, 0.02460850111856816, -0.0021834061135370675, 0.006564551422319376, -0.01521739130434785, 0.019867549668874274, 0.015151515151515138, 0.019189765458422103, 0.0020920502092049986, 0.0041753653444676075, -0.037422037422037424, -0.025917926565874768, 0.05764966740576494, -0.018867924528301886, -0.05982905982905984, 0.05000000000000005, 0.06060606060606055, 0.04693877551020398, 0.0038986354775829572, 0.01941747572815533, 0.0647619047619048, -0.04472271914132375, -0.011235955056179804, -0.003787878787878785, 0.0, 0.0323193916349811, 0.04051565377532218, -0.0035398230088495852, 0.014209591474245054, -0.03327495621716292, -0.003623188405797117, 0.05818181818181811, 0.012027491408934663, -0.02886247877758918, 0.0, 0.06643356643356646, 0.003278688524590123, -0.004901960784313708, -0.01970443349753692, 0.01842546063651596, -0.06414473684210531, 0.012302284710017595, 0.013888888888888841, -0.056506849315068435, 0.05444646098003636, -0.02237521514629948, -0.02640845070422537, -0.06329113924050632, 0.02509652509652516, -0.03766478342749524, 0.03718199608610573, 0.007547169811320753, -0.16104868913857673, 0.03125, -0.03030303030303028, 0.0245535714285714, -0.04793028322440085, 0.04347826086956519, 0.030701754385964893, -0.017021276595744702, 0.03463203463203457, -0.006276150627615107, -0.05684210526315792, 0.01116071428571419, 0.13907284768211925, -0.023255813953488413, -0.009920634920634884, -0.040080160320641316, 0.014613778705636847, -0.06378600823045266, -0.00219780219780219, 0.0022026431718060735, -0.08791208791208792, -0.04337349397590362, 0.05037783375314864, -0.014388489208633115, -0.03649635036496346, 0.05050505050505062, -0.043269230769230727, 0.025125628140703515, 0.0269607843137254, -0.04534606205250602, 0.0, -0.0050000000000000044, -0.12060301507537685, 0.0028571428571428914, -0.03703703703703709, 0.047337278106508895, 0.028248587570621538, 0.008241758241758212, -0.019073569482288773, 0.013888888888888841, -0.03013698630136985, -0.07627118644067797, -0.05504587155963303, -0.07766990291262132, 0.0736842105263158, 0.019607843137254832, 0.02564102564102555, -0.018750000000000044, -0.07006369426751591, -0.0821917808219178, 0.033582089552238736, -0.02166064981949456, -0.05166051660516602, -0.03891050583657585, 0.03921568627450989, 0.02641509433962264, 0.022058823529411686, 0.010791366906474751, 0.04982206405693956, -0.016949152542372836, -0.0482758620689655, -0.025362318840579712, -0.01941747572815533, -0.035031847133757954, -0.07590759075907594]}, {\"name\": \"predicted\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], \"y\": [0.02292887680232525, 0.015502911061048508, -0.0020493417978286743, 0.0022344067692756653, 0.016725193709135056, 0.023659957572817802, 0.0089472196996212, -0.00731629878282547, -0.005757838487625122, 0.0062415711581707, -0.04082886129617691, -0.02940763533115387, 0.04627835750579834, -0.02113967016339302, 0.000980272889137268, 0.06999098509550095, 0.058552928268909454, 0.021148324012756348, 0.005362033843994141, 0.006622225046157837, 0.013908760622143745, -0.016760218888521194, -0.01862408220767975, 0.009186377748847008, 0.014417935162782669, 0.03650720417499542, 0.025733746588230133, -0.01461954414844513, -0.0014907419681549072, 0.004046536982059479, 0.011837923899292946, 0.030625708401203156, 0.007792174816131592, -0.018526457250118256, 0.03247945383191109, 0.04455384984612465, -0.013219133019447327, -0.025113597512245178, -0.003961704671382904, -0.0005805082619190216, -0.03275252878665924, -0.0006485618650913239, 0.006605394184589386, -0.015378646552562714, 0.009183619171380997, -0.023524239659309387, -0.039497703313827515, -0.02874165028333664, 0.008943364024162292, -0.003258034586906433, -0.011723417788743973, -0.03641423583030701, -0.09914238750934601, 0.028338395059108734, -0.017804346978664398, -0.0043035708367824554, -0.007910545915365219, 0.03333890065550804, 0.03817000985145569, -0.0009491071105003357, 0.008885174989700317, -0.01555664837360382, -0.029575206339359283, 0.041935428977012634, 0.08291533589363098, -0.015450645238161087, -0.029708385467529297, -0.02456345409154892, -0.014692924916744232, -0.025435395538806915, -0.02010243386030197, -0.02216877043247223, -0.05757050961256027, -0.010539084672927856, 0.024228200316429138, -0.00811149924993515, -0.013917934149503708, 0.019829444587230682, -0.005587227642536163, 0.011068658903241158, 0.0068425461649894714, -0.01801116392016411, -0.025069206953048706, -0.03234192728996277, -0.049574702978134155, -0.014775339514017105, 0.0019017122685909271, 0.012604568153619766, 0.0009542033076286316, -0.014436796307563782, -0.020294751971960068, -0.030728697776794434, -0.04077797383069992, -0.055154792964458466, -0.04884099215269089, -0.020771730691194534, 0.04597574844956398, 0.0383770577609539, 0.006885487586259842, -0.03078571707010269, -0.06971979141235352, -0.047212086617946625, 0.003650754690170288, -0.0232388973236084, -0.048285096883773804, -0.017272643744945526, 0.019418664276599884, 0.033458881080150604, 0.0312894806265831, 0.020411891862750053, 0.0098477303981781, -0.004096522927284241, -0.023632779717445374, -0.024489954113960266, -0.034578241407871246, -0.0674264058470726, -0.07547461986541748]}],\n",
       "                        {\"legend\": {\"orientation\": \"h\"}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"code: A507\"}, \"xaxis\": {\"title\": {\"text\": \"Time\"}}, \"yaxis\": {\"title\": {\"text\": \"Earning Ratio (target)\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('81998772-9bf4-401f-a6e8-ba7920dd08af');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code 'A507' 학습 (100 epoch)\n",
    "lstm_train_visualize(train_df, 'A507', feat_cols, num_epochs=100, seq_len=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/300]  train_loss: 0.01827\n",
      "Epoch [40/300]  train_loss: 0.01397\n",
      "Epoch [60/300]  train_loss: 0.00974\n"
     ]
    }
   ],
   "source": [
    "# code 'A507' 학습 (300 epoch)\n",
    "lstm_train_visualize(train_df, 'A507', feat_cols, num_epochs=300, seq_len=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 이미지는 위 코드 각각의 실행 결과이다 (출력이 안되어 있을 경우를 대비하여 올려놨습니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![predict1](https://user-images.githubusercontent.com/40786348/73937478-75143700-4928-11ea-8fd5-f071cb398f5a.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![predict2](https://user-images.githubusercontent.com/40786348/73937530-9543f600-4928-11ea-859a-c97bd23e4b30.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![predict3](https://user-images.githubusercontent.com/40786348/73937537-9bd26d80-4928-11ea-8b6d-c0c096ebf95c.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "복잡한 구조의 모델이 아닌 RNN layer 두 개와 fc layer 한 개만을 활용 했음에도 불구하고 잘 학습이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 주식 데이터셋을 활용하여 다음 시간 단위의 수익률을 예측하는 모델링 과정을 살펴보았다. 총 학습 시간은 1시간도 안걸릴 정도로 매우 짧다.\n",
    "<br>\n",
    "본인이 이미지, 자연어, 음성 등과 같은 타 문제를 기반으로 AI 모델링을 모두 수행해 본 결과, 모든 부분에서 정교함이 요구되기 때문에 주가 예측 모델링이 그 중에서 가장 어려운 축에 속하지 않을까 하는 생각이 든다.\n",
    "<br>\n",
    "encoder/decoder, attention 기반의 모델 구조, GAN을 활용한 unsupervised 기반의 모델링 등 다양한 관점에서 문제를 해결할 수도 있을 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('py36': conda)",
   "language": "python",
   "name": "python37564bitpy36condaca33cc43c1994fa08616385a83729a3a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
